# 超越RAG的agentic search :从“被动投喂”到“主动探索”-Anthropic《AI Agent的高效上下文工程》③ - 整理版

## 视频信息
- 作者：慢学AI
- 时长：269.566秒
- 平台：bilibili
- 链接：https://www.bilibili.com/video/BV1gJxVzMEfW/?spm_id_from=333.337.search-card.all.click&vd_source=2237a6a04aa93d29745585f9dbc923fe

## 内容整理

# 你的AI助手为什么总是答非所问？揭秘让它变聪明的秘密

你有没有遇到过这样的情况：向AI提出一个问题，它却给你一堆看似相关、实则答非所问的内容？或者在处理复杂任务时，AI总是卡在某个环节无法继续？这背后的根本原因，其实是它获取信息的方式出了问题。

在前两期内容中，我们已经为AI打造了一个"大脑"——通过上下文工程明确了AI的工作原理，并学会了构建高质量的静态上下文，也就是AI的出场设置。但一个只有静态知识的大脑，就像一个只会背书的学生，无法应对真实世界的复杂挑战。今天，我们要解决的核心问题是：**如何让AI像人类一样，能够主动寻找信息、动态思考？**

## Connection：封闭的困境

想象一下，你让一个只能看固定教材的学生去解决一个开放性问题。无论他多么聪明，如果手头的资料不够或者方向错了，他都无法给出满意的答案。AI面临的困境也是如此。

如果一个AI智能体（agent）只能依赖预设的知识工作，那它就是一个封闭系统。现实中的任务远比这复杂得多——你可能需要它分析最新的市场数据、查找特定代码文件、或者综合多个来源的信息。这时候，**如何将海量的外部信息高效又精准地注入到有限的上下文环境里**，就成了关键挑战。

这个问题的本质是：AI的"工作记忆"是有限的，但外部世界的信息是无限的。如何在这两者之间建立高效的桥梁？

## Conflict：两种截然不同的信息获取方式

面对这个挑战，业界发展出了两种截然不同的解决方案，它们代表了两种完全不同的思维模式。

### 推理前检索：图书馆管理员模式

第一种方式叫做**推理前检索**（RAG，Retrieval-Augmented Generation）。它的工作逻辑非常清晰：

当你提出一个问题后，系统会先把问题转换为向量表示，然后在向量数据库中查找语义相似的文档片段，取出最相关的几条内容拼接到上下文中，最后交给大模型生成答案。这是一条单向的流水线——在模型开始思考之前，所有资料就已经准备好了。

打个比方，这就像图书馆管理员模式。你告诉管理员一个主题，他去书库翻找资料，挑出几本相关的书放到专家桌上，专家再根据这些书回答问题。整个流程稳定、速度快，一次检索、一次调用，成本低廉，特别适合应对常规情况。

但这种方式存在三个明显问题。**第一**，信息可能过时。预先准备的资料无法保证是最新的。**第二**，检索不够智能。基于向量相似度的匹配容易拿到语义偏差的内容，反而污染上下文。**第三**，无法探索未知领域。一旦输入方向错误，就会被锁死在错误的检索结果里，模型只能被动等待信息投喂，无法自主调整方向。

### 及时检索：侦探探案模式

第二种方式叫做**及时检索**（Agentic Search）。在这种模式下，模型不再被动接受信息，而是主动探索。整个过程是循环动态的。

用户提问后，模型会先思考是否需要调用工具。它可能先执行"列出文件"命令，查看有哪些可用资源；再根据返回结果选择打开其中一个文件，读取前几行内容；然后观察新信息，决定下一步是继续搜索别的路径，还是已经有足够信息可以直接生成答案。

及时检索的核心在于：**上下文的构建不再是推理前的一次性准备，而是推理过程中的动态迭代**。

这就像一个侦探破案。拿到案子后，侦探会自己去档案室查目录、翻看笔记、比对证据。每发现一个线索，就更新推理方向；每个新发现，都可能改变整个调查路径。

这种方式带来了三个显著优势。**首先**，信息永远是最新的，因为每一步都是及时调用工具获取，不存在信息过期问题。**其次**，信噪比高，只取当下真正需要的信息，不会被无关内容淹没。**最后**，具备探索能力，遇到模糊问题时可以边查边想、边想边查，对于复杂的多步推理任务尤其关键。

## Change：智能探索的两大机制

那么，agent是如何做到智能探索的呢？这背后有两个关键机制。

**第一个是元数据理解**。Agent不仅看内容本身，还能理解内容的信息结构。比如，一个叫`test-utils.py`的文件放在`test`文件夹里，这个命名和位置就表明该文件是用于测试的。数据库表名、网页链接地址、文件更新时间等，都能成为它判断方向的信号——就像人类看到文件夹名称、时间戳、目录结构时，会自然猜测其作用一样。

**第二个机制是渐进式披露**。这个概念借鉴自用户体验设计，意思是不要一次性把所有信息都塞给模型，而是让它自己逐步发现，一层一层揭开需要的上下文。这样模型能始终聚焦在最相关的任务子集上，不会因信息过多而分心。可以理解为，它学会了"按需思考"。

## Catch：混合策略才是最优解

那么，这两种方式哪个更好呢？其实各有取舍。

RAG的优势是速度快、结构简单，适合知识问答、客服、固定流程任务。Agentic Search的优势是灵活、能探索未知领域，更适合研究、编程、分析类任务。

在真正复杂的产品里，**最优解往往是混合策略**。比如Claude的代码助手Clode Code，启动时会预先加载一份`claud.md`文件，让模型对整个项目有初步理解——这部分属于RAG。同时，它也配备了像`GlobeDrop`这样的工具，能在运行时及时检索文件、分析数据——这部分就是Agentic Search。这样既保留了速度优势，又具备了探索能力。

---

**总结一下**，我们已经帮agent装上了"静态大脑"，又赋予了它"动态感官"。它不仅能想，还能找、能看、能探索。但故事还没结束——当任务持续数小时甚至几天，agent该怎么记住过去的决策，避免在长时间任务中遗忘关键信息呢？

这就是下一期要讲的内容：**如何为长期任务构建上下文**？我们会介绍三种高级架构，让agent真正具备持续思考的能力。到那时，你的AI助手将不再是一个健忘的工具，而是一个真正能够长期协作的智能伙伴。
# 超越RAG的agentic search :从“被动投喂”到“主动探索”-Anthropic《AI Agent的高效上下文工程》③

## 视频信息
- 作者：慢学AI
- 时长：269.566秒
- 平台：bilibili
- 链接：https://www.bilibili.com/video/BV1gJxVzMEfW/?spm_id_from=333.337.search-card.all.click&vd_source=2237a6a04aa93d29745585f9dbc923fe

## 原始转录内容

前两期我们分别探讨了不同内容。第一期我们明确了什么是上下文工程,以及它的重要性。第二期我们学会了构建高质量的静态上下文,也就是AI的出场设置。而这一期我们将进入更具生命力的部分,动态生下国。这是让AIagent真正活起来的关键。可以说前两期我们造出了大脑,这一期要让这个大脑开始感知世界。我们先从一个简单问题入手。如果一个agent只能依赖出场设置工作,那它就是一个封闭系统。但现实中的任务远比这复杂,还需要探索新信息。那么如何将海量外部信息高效又精准的注入到有限的上限环境里呢?今天我们来讲两种动态信息检索的核心范式,推理前检索和及时检索。首先讲推理前检索,它的工作逻辑很清晰。用户提出问题后,系统先把问题转换为向量,然后在向量数据库中查找相似的文档片段。取出最相关的几条拼到上下文了,最后交给大模型生成答案。这是一条单向的流水线,在模型开始思考之前就已经提前准备好了资料。打个比方,这就像图书馆管理员模式,你告诉管理员一个主题,他去书库翻资料,挑出几本相关的书放到专家桌上,专家再根据这些书回答问题。这种流程稳定速度快,一次检索,一次调用,成本低,安整紧的情况。但也存在明显问题,一是信息可能过时,二是检索不够智能,容易拿到语意偏差的内容污染上下文。三是无法探索,一旦输入方向错误,就会被锁死在错误的检索结果里。模型只能被动等待信息投位,接下来看及时检索。在这种方式中,模型不再被动,而是主动的,整个过程是循环动态的。用户提问后,模型先思考是否要调用工具,他可能先执行List files,查看有哪些文件。再根据返回结果选择打开,其中一个并读取前几行,然后观察新信息。下一步是搜索别的路径还是直接生成答案。及时检索的核心在于,上下围的构建不再是推理前的一次性准备,而是推理过程中的动态迭代。打个比方,他就像一个侦探,拿到案子后自己去档案室查目录,看笔记,比对证据,每发现一个线索就更新推理方向。这种方式有明显好处,一是信息永远是最新的,因为每一步都是及时调用工具,不存在信息过期问题。二是信造比高,只取当下真正需要的信息,不会被无关内容淹没。三是具备探索能力,遇到模糊问题时可以边查边想,边想边查。对于复杂的多步推理任务尤其关键,agent能做到智能探索,有两个关键机制。第一个是原数据,agent不仅看内容,还能理解内容的信息结构。比如,一个叫test-utils.py的文件放在test文件夹里,这就表明该文件是用于测试的。像数据库表明、网页链接地址、文件更新时间等,都能成为它判断方向的信号。就像人类看到文件夹明,时间戳,护路结构会自然猜测其作用一样。第二个机制是渐进式披露,这一概念借自用户体验设计。意思是不要一次性把所有信息都塞给模型,而是让它自己逐步发现,一层一层揭开需要的上下文。这样模型能始终聚焦在最相关的任务子机上,不会因信息过多而分心,可以理解为它学会了按需思考。那么这两种方式哪个更好呢?其实各有取舍。RAG的优势是速度快、结构简单、适合知识问答、克服、固定流程任务。Agenic Search的优势是灵活、能探索未知领域,更适合研究、编程、分析类任务。在真正复杂的产品里,最优解往往是混合策略。比如Cloud Code,启动时会预先加载一份clud.md文件,让模型对整个项目有初步理解。这部分属于RAG,同时它也配备了像GlobeDrop这样的工具,能在运行时及时检索文件。分析数据,这部分就是Agenic Search,这样既保留了速度,又具备了探索能力。总结一下,我们已经帮agent装上了静态大脑,又赋予了它动态感官。它不仅能想,还能找,能看,能探索。不过故事还没结束,当任务持续数小时甚至几天,agent该怎么记住过去,以免在长时间任务中遗忘关键决策呢?这就是下一期要讲的内容。如何为长期任务构建上下文?我们会介绍三种高级架构,让agent真正具备持续思考的能力。如果你觉得本期视频对你有用,欢迎一键三连。
# 超越RAG的agentic search :从“被动投喂”到“主动探索”-Anthropic《AI Agent的高效上下文工程》③ - 整理版

## 视频信息
- 作者：慢学AI
- 时长：269.566秒
- 平台：bilibili
- 链接：https://www.bilibili.com/video/BV1gJxVzMEfW/?spm_id_from=333.337.search-card.all.click&vd_source=2237a6a04aa93d29745585f9dbc923fe

## 内容整理

# 你的AI助手为什么总是答非所问？动态上下文才是破局关键

你有没有遇到过这样的情况：向AI提问时，它给出的答案看似有理有据，实际上却完全偏离了你的需求？或者，你明明提供了足够的背景信息，它却视而不见，依然按照自己的"理解"回答？

问题的根源在于：一个只依赖初始设置的AI，就像一个被关在密室里的专家——无论他多么博学，如果看不到外面的世界，也无法给出真正有用的答案。这就是为什么我们需要**动态上下文**。

在前两期内容中，我们已经搭建了AI的"大脑"：第一期明确了上下文工程的重要性，第二期学会了构建高质量的静态上下文。而今天，我们要让这个大脑真正"活"起来——赋予它感知世界、主动探索的能力。

## 封闭系统的困境

想象一下，你正在使用一个AI编程助手。你问它："这个项目里的测试文件在哪里？"如果这个AI只能依赖出场设置工作，它就像一个被蒙住眼睛的人，只能根据有限的记忆猜测答案。

现实中的任务远比这复杂。项目会更新，文件会移动，需求会变化。一个真正有用的AI助手，必须能够实时获取最新信息，而不是困在过时的知识里。

那么问题来了：**如何将海量的外部信息，高效又精准地注入到有限的上下文环境里？**

## 图书馆管理员模式：推理前检索

第一种方案叫做**推理前检索**（RAG），它的工作流程就像图书馆里的管理员：

你走进图书馆，告诉管理员你想了解某个主题。管理员立即去书库翻找，挑出几本最相关的书，整齐地摆在专家桌上。然后，专家根据这些书给出答案。

技术上，这个过程是这样的：用户提出问题后，系统先把问题转换为向量表示，然后在向量数据库中查找语义相似的文档片段，取出最相关的几条拼接到上下文里，最后交给大模型生成答案。

这是一条**单向的流水线**：在模型开始思考之前，资料就已经准备好了。一次检索，一次调用，流程稳定，速度快，成本低，特别适合知识问答、客服、固定流程任务。

但这种方式也有明显的局限：

首先，**信息可能过时**。如果数据库里的内容没有及时更新，AI就会基于旧信息做出判断。

其次，**检索不够智能**。向量相似度并不等于真正的相关性，很容易拿到语义偏差的内容，反而污染上下文。

最关键的是，**无法探索**。一旦输入方向错误，就会被锁死在错误的检索结果里。模型只能被动等待信息投喂，没有自主调整的能力。

## 侦探模式：即时检索

第二种方案叫做**即时检索**（Agentic Search），它让AI从被动接受者变成主动探索者。

想象一个侦探拿到一个案子：他不会等别人把所有档案整理好送过来，而是自己去档案室查目录、看笔记、比对证据。每发现一个线索，就更新推理方向，决定下一步该查什么。

在这种方式中，整个过程是**循环动态的**。用户提问后，模型先思考是否需要调用工具。它可能先执行"列出文件"命令，查看有哪些文件；再根据返回结果选择打开其中一个，读取前几行；然后观察新信息，决定下一步是继续搜索别的路径，还是直接生成答案。

即时检索的核心在于：**上下文的构建不再是推理前的一次性准备，而是推理过程中的动态迭代。**

这种方式有三个明显优势：

**信息永远是最新的。**因为每一步都是即时调用工具，不存在信息过期问题。

**信噪比高。**只取当下真正需要的信息，不会被无关内容淹没。

**具备探索能力。**遇到模糊问题时可以边查边想、边想边查，对于复杂的多步推理任务尤其关键。

## 智能探索的两个关键机制

让AI真正具备探索能力，需要两个关键机制。

第一个是**元数据理解**。AI不仅看内容本身，还能理解内容的信息结构。比如，一个叫`test-utils.py`的文件放在`test`文件夹里，这就表明该文件是用于测试的。数据库表名、网页链接地址、文件更新时间等，都能成为它判断方向的信号——就像人类看到文件夹名、时间戳、路径结构会自然猜测其作用一样。

第二个机制是**渐进式披露**。这一概念借自用户体验设计，意思是不要一次性把所有信息都塞给模型，而是让它自己逐步发现，一层一层揭开需要的上下文。这样模型能始终聚焦在最相关的任务子集上，不会因信息过多而分心。可以理解为，它学会了**按需思考**。

## 最优解：混合策略

那么这两种方式哪个更好呢？答案是：**各有取舍，混合使用才是王道。**

推理前检索（RAG）的优势是速度快、结构简单，适合知识问答、客服、固定流程任务。即时检索（Agentic Search）的优势是灵活、能探索未知领域，更适合研究、编程、分析类任务。

在真正复杂的产品里，最优解往往是混合策略。比如Claude的Code功能，启动时会预先加载一份`claude.md`文件，让模型对整个项目有初步理解——这部分属于RAG。同时，它也配备了像`GlobSearch`这样的工具，能在运行时即时检索文件、分析数据——这部分就是Agentic Search。这样既保留了速度，又具备了探索能力。

## 下一步：记忆的挑战

现在，我们已经帮AI装上了静态大脑，又赋予了它动态感官。它不仅能想，还能找、能看、能探索。

但故事还没结束。当任务持续数小时甚至几天，AI该怎么记住过去的决策？如何避免在长时间任务中遗忘关键信息？

这就是下一期要讲的内容：**如何为长期任务构建上下文？**我们会介绍三种高级架构，让AI真正具备持续思考的能力。